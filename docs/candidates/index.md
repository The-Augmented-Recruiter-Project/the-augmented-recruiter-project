# Candidate Perspective

This section approaches AI-assisted recruiting from the standpoint of candidates and applicants — people who are subjected to hiring systems but do not choose or control them.

It exists to document what candidates should reasonably expect, what they can question, and where current practice often falls short.

This section is not written for system buyers.

---

## Why this section exists

Recruiting systems are typically designed, evaluated, and procured without meaningful input from candidates.

As a result:
- automation is often invisible
- explanations are partial or misleading
- responsibility is unclear when systems fail
- candidates are expected to adapt without recourse

This section treats candidates as first-class stakeholders rather than downstream users.

---

## What candidates should know

### What is typically automated
- Where automation is commonly used in recruiting workflows
- What signals are likely machine-generated or machine-influenced
- Where human review often stops earlier than claimed

### What is rarely automated (despite assumptions)
- Final hiring decisions
- Legal responsibility
- Interpretive judgment in edge cases

---

## Transparency and explanation

### Disclosure of AI use
- What meaningful disclosure looks like in practice
- Where disclosure becomes performative
- Common patterns of partial disclosure

### Explanation vs understanding
- Why explanations do not always lead to clarity
- The limits of technical explainability for candidates
- When “explanation” functions as reassurance rather than information

---

## Consent, choice, and control

### The reality of consent
- Why consent in hiring is rarely free or symmetrical
- How consent is often bundled or implied

### Opt-out and alternatives
- When opt-outs exist only in theory
- What realistic alternatives look like (and where they don’t)

---

## Contestability and recourse

### Questioning outcomes
- What candidates can reasonably ask
- What organisations should be able to answer

### Appeals and challenges
- Where appeal mechanisms exist
- Where they collapse under scale or opacity

---

## Power asymmetry and harm

### Structural imbalance
- Why candidates carry most of the risk
- How automation amplifies existing asymmetries

### Common candidate harms
- Silent exclusion
- False objectivity
- Lost opportunity without explanation

---

## Open questions

- What does meaningful transparency look like at scale?
- When does explanation meaningfully change outcomes?
- How much recourse is realistic in high-volume hiring?
- Where should human judgment be mandatory rather than optional?

These questions are left open intentionally.
