# Evaluation & Testing

This section documents ways of evaluating AI-assisted recruiting systems that go beyond performance claims or vendor metrics.

Evaluation here is concerned with:
- how systems behave in practice
- how humans interact with them
- how outcomes change over time
- where responsibility quietly shifts or disappears

Testing is treated as an **ongoing practice**, not a one-time validation step.

---

## What evaluation means in this project

Evaluation is not about proving that a system is “accurate” or “fair”.

It is about answering questions such as:
- What does this system actually do in a real hiring flow?
- How stable is its behaviour under small changes?
- How do candidates and hiring managers interpret it?
- What decisions does it influence indirectly?
- How does it reshape the hiring funnel over time?

Many important failures in recruiting AI do not show up in dashboards.  
They show up in behaviour, confusion, silence, or gradual drift.

---

## Types of evaluation documented here

This section includes multiple, complementary approaches:

- **Controlled input testing**  
  Using fixed or shared inputs (e.g. anonymised CV sets) to probe consistency, sensitivity, and thresholds.

- **Contextual interaction testing**  
  Informal, human-centred testing of how people experience and respond to AI-mediated interactions in recruiting flows.

- **Funnel-level and longitudinal analysis**  
  Examining how hiring outcomes, drop-off points, and behaviour change over time after AI is introduced.

- **Sanity checks and desk-side review**  
  Structured human review of system outputs in context, outside formal reporting environments.

No single method is sufficient on its own.

---

## Limits of evaluation

Evaluation methods documented here:
- do not certify compliance
- do not guarantee fairness
- do not generalise across contexts
- do not replace human responsibility

They are intended to surface risk, ambiguity, and unintended consequences early — while there is still room to intervene.

---

## Status

This section will be built incrementally.

Methods are added only where they clarify real behaviour or reveal failure modes that are otherwise easy to miss.
